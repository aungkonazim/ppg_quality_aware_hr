{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virtual-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X,y_hr,y_participant,y_activity = pickle.load(open('../data/heart_rate_tabular_data_ppg_dalia.p','rb'))\n",
    "activity_dict1 = {'No Label':-1,'Sitting':0,'Stairs':1,'Soccer':2,\n",
    "                'Cycling':3,'Driving':4,'Lunch':-1,'Walking':5,\n",
    "                'Working':-1}\n",
    "y_activity = np.array([activity_dict1[a] for a in y_activity])\n",
    "X = X[:,:,1:].reshape(-1,256,3)\n",
    "X = X[y_activity==5]\n",
    "min1,max1 = np.min(X),np.max(X)\n",
    "cc = np.max(np.abs(X))\n",
    "X = X/cc\n",
    "# X = X/np.max(X)\n",
    "y_activity = OneHotEncoder().fit_transform(y_activity.reshape(-1,1)).todense()\n",
    "activity_dict_reverse = {activity_dict1[key]:key for key in activity_dict1.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alleged-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a in X:\n",
    "#     plt.figure(figsize=(5,3))\n",
    "#     plt.plot(a*cc)\n",
    "#     plt.ylim([min1, max1])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "future-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-incident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 3)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 128, 64)           3904      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 64, 128)           82048     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 128)           163968    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16, 128)           163968    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 415,937\n",
      "Trainable params: 415,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv_block(x,filters,activation,kernel_size=(3, 3),strides=(1, 1),\n",
    "               padding=\"same\",use_bias=True,use_bn=False,\n",
    "               use_dropout=False,drop_value=0.5):\n",
    "    \n",
    "    x = layers.Conv1D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias)(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_discriminator_model(input_shape = (256,3)):\n",
    "    \n",
    "    input_ = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = conv_block(input_,64,kernel_size=20,strides=2,use_bn=False,use_bias=True,\n",
    "        activation=layers.LeakyReLU(0.2),use_dropout=False,drop_value=0.3)\n",
    "    \n",
    "    x = conv_block(x,128,kernel_size=10,strides=2,use_bn=False,activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,use_dropout=True,drop_value=0.3)\n",
    "    \n",
    "    x = conv_block(x,128,kernel_size=10,strides=2,use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),use_bias=True,use_dropout=True,drop_value=0.3)\n",
    "    \n",
    "    x = conv_block(x,128,kernel_size=10,strides=2,use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),use_bias=True,use_dropout=True,drop_value=0.3)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = layers.Dense(1)(x)\n",
    "\n",
    "    d_model = keras.models.Model(input_, x, name=\"discriminator\")\n",
    "    \n",
    "    return d_model\n",
    "\n",
    "\n",
    "d_model = get_discriminator_model(input_shape=(256,3))\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sophisticated-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12800     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d (UpSampling1D) (None, 256, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 256, 128)          2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 128)          512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 512, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 512, 64)           163840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512, 64)           256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 256, 64)           163904    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 256, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 256, 3)            3843      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 3)            0         \n",
      "=================================================================\n",
      "Total params: 348,227\n",
      "Trainable params: 347,587\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def upsample_block(x,filters,activation,kernel_size=20, strides=1, up_size=2, \n",
    "                    padding=\"same\",use_bn=False,use_bias=True,\n",
    "                    use_dropout=False,drop_value=0.3):\n",
    "    \n",
    "    x = layers.UpSampling1D(up_size)(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias)(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "        \n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_generator_model(latent_size=100,first_dense_shape=128):\n",
    "    noise = layers.Input(shape=(latent_size,))\n",
    "    \n",
    "    x = layers.Dense(first_dense_shape, use_bias=False)(noise)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Reshape((128,1))(x)\n",
    "    \n",
    "    \n",
    "    x = upsample_block(x,128, layers.LeakyReLU(0.2), strides=1, use_bias=False,\n",
    "                       use_bn=True, padding=\"same\", use_dropout=False)\n",
    "    \n",
    "    x = upsample_block(x, 64, layers.LeakyReLU(0.2), strides=1, use_bias=False,\n",
    "                       use_bn=True, padding=\"same\", use_dropout=False)\n",
    "    \n",
    "    x = conv_block(x,64,kernel_size=40,strides=2,use_bn=False,use_bias=True,\n",
    "                   activation=layers.LeakyReLU(0.2),use_dropout=False,drop_value=0.3)\n",
    "    \n",
    "    x = conv_block(x,3,kernel_size=20,strides=1,use_bn=False,use_bias=True,\n",
    "                  activation=layers.Activation('tanh'),use_dropout=False,drop_value=0.3)\n",
    "    \n",
    "    g_model = keras.models.Model(noise, x, name=\"generator\")\n",
    "    \n",
    "    \n",
    "    return g_model\n",
    "\n",
    "\n",
    "g_model = get_generator_model()\n",
    "g_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "general-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "    ):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper:\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add the gradient penalty to the discriminator loss\n",
    "        # 6. Return the generator and discriminator losses as a loss dictionary\n",
    "\n",
    "        # Train the discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator. Here we will train it for 3 extra steps\n",
    "        # as compared to 5 to reduce the training time.\n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(batch_size, self.latent_dim)\n",
    "            )\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = self.generator(random_latent_vectors, training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_images, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_images, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_images = self.generator(random_latent_vectors, training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "preliminary-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=6, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        for i in range(self.num_img):\n",
    "            img = generated_images[i].numpy()*cc\n",
    "            \n",
    "            plt.figure(figsize=(5,3))\n",
    "            plt.plot(img)\n",
    "#             img = keras.preprocessing.image.array_to_img(img)\n",
    "            plt.ylim([min1,max1])\n",
    "            plt.savefig(\"./images/generated_img_{i}_{epoch}.png\".format(i=epoch, epoch=i))\n",
    "            plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "harmful-fight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "24/24 [==============================] - 3s 114ms/step - d_loss: -3.9156 - g_loss: 11.2181\n",
      "Epoch 2/60\n",
      "24/24 [==============================] - 2s 98ms/step - d_loss: -2.4199 - g_loss: 6.3643\n",
      "Epoch 3/60\n",
      "24/24 [==============================] - 2s 97ms/step - d_loss: -2.1260 - g_loss: 3.6005\n",
      "Epoch 4/60\n",
      "24/24 [==============================] - 2s 99ms/step - d_loss: -2.5216 - g_loss: 3.1041\n",
      "Epoch 5/60\n",
      "24/24 [==============================] - 2s 99ms/step - d_loss: -2.6371 - g_loss: 3.3060\n",
      "Epoch 6/60\n",
      "24/24 [==============================] - 2s 98ms/step - d_loss: -2.5914 - g_loss: 3.2806\n",
      "Epoch 7/60\n",
      "24/24 [==============================] - 2s 98ms/step - d_loss: -2.4808 - g_loss: 3.1452\n",
      "Epoch 8/60\n",
      "24/24 [==============================] - 2s 99ms/step - d_loss: -2.3450 - g_loss: 3.2172\n",
      "Epoch 9/60\n",
      "24/24 [==============================] - 2s 99ms/step - d_loss: -2.0137 - g_loss: 2.8938\n",
      "Epoch 10/60\n",
      "24/24 [==============================] - 2s 98ms/step - d_loss: -1.8767 - g_loss: 3.2351\n",
      "Epoch 11/60\n",
      "24/24 [==============================] - 2s 98ms/step - d_loss: -1.7940 - g_loss: 3.1314\n",
      "Epoch 12/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.5616 - g_loss: 3.0837\n",
      "Epoch 13/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.5796 - g_loss: 3.1309\n",
      "Epoch 14/60\n",
      "24/24 [==============================] - 3s 106ms/step - d_loss: -1.5433 - g_loss: 4.0841\n",
      "Epoch 15/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.2914 - g_loss: 5.0575\n",
      "Epoch 16/60\n",
      "24/24 [==============================] - 2s 99ms/step - d_loss: -1.3357 - g_loss: 3.6261\n",
      "Epoch 17/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.5284 - g_loss: 6.1089\n",
      "Epoch 18/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -1.2198 - g_loss: 7.2030\n",
      "Epoch 19/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.2771 - g_loss: 7.1297\n",
      "Epoch 20/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -1.0441 - g_loss: 6.6251\n",
      "Epoch 21/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.0929 - g_loss: 6.4370\n",
      "Epoch 22/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.0846 - g_loss: 6.6884\n",
      "Epoch 23/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.0328 - g_loss: 5.4736\n",
      "Epoch 24/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.0115 - g_loss: 5.6915\n",
      "Epoch 25/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.0056 - g_loss: 4.6952\n",
      "Epoch 26/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.0098 - g_loss: 4.7821\n",
      "Epoch 27/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9764 - g_loss: 4.4541\n",
      "Epoch 28/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -0.8635 - g_loss: 4.3607\n",
      "Epoch 29/60\n",
      "24/24 [==============================] - 3s 109ms/step - d_loss: -0.9955 - g_loss: 4.9324\n",
      "Epoch 30/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9141 - g_loss: 3.7019\n",
      "Epoch 31/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -0.9239 - g_loss: 2.9621\n",
      "Epoch 32/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9799 - g_loss: 1.9204\n",
      "Epoch 33/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.8607 - g_loss: 2.1184\n",
      "Epoch 34/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9143 - g_loss: 2.4011\n",
      "Epoch 35/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.8465 - g_loss: 2.0994\n",
      "Epoch 36/60\n",
      "24/24 [==============================] - 2s 102ms/step - d_loss: -0.8859 - g_loss: 0.8484\n",
      "Epoch 37/60\n",
      "24/24 [==============================] - 2s 102ms/step - d_loss: -1.0139 - g_loss: 0.9910\n",
      "Epoch 38/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9529 - g_loss: 0.5785\n",
      "Epoch 39/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.0173 - g_loss: 0.8724\n",
      "Epoch 40/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9539 - g_loss: 0.8142\n",
      "Epoch 41/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9478 - g_loss: -0.5196\n",
      "Epoch 42/60\n",
      "24/24 [==============================] - 2s 102ms/step - d_loss: -0.9659 - g_loss: -0.1108\n",
      "Epoch 43/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -0.8459 - g_loss: -0.2502\n",
      "Epoch 44/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -1.0474 - g_loss: -0.5755\n",
      "Epoch 45/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9679 - g_loss: -0.6708\n",
      "Epoch 46/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9702 - g_loss: -0.1873\n",
      "Epoch 47/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -1.0410 - g_loss: -0.1938\n",
      "Epoch 48/60\n",
      "24/24 [==============================] - 3s 111ms/step - d_loss: -1.0249 - g_loss: 0.3222\n",
      "Epoch 49/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9095 - g_loss: 0.5669\n",
      "Epoch 50/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -1.0236 - g_loss: 0.8004\n",
      "Epoch 51/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -0.9601 - g_loss: 0.8310\n",
      "Epoch 52/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.8872 - g_loss: 0.8039\n",
      "Epoch 53/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9863 - g_loss: 0.5726\n",
      "Epoch 54/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9890 - g_loss: 0.1670\n",
      "Epoch 55/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9735 - g_loss: 0.7205\n",
      "Epoch 56/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9560 - g_loss: 0.3473\n",
      "Epoch 57/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9169 - g_loss: 0.6910\n",
      "Epoch 58/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -1.0096 - g_loss: 0.5823\n",
      "Epoch 59/60\n",
      "24/24 [==============================] - 2s 101ms/step - d_loss: -0.9608 - g_loss: 0.8078\n",
      "Epoch 60/60\n",
      "24/24 [==============================] - 2s 100ms/step - d_loss: -0.9522 - g_loss: 1.4639\n"
     ]
    }
   ],
   "source": [
    "noise_dim = 100\n",
    "BATCH_SIZE = 200\n",
    "generator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "\n",
    "# Define the loss functions for the discriminator,\n",
    "# which should be (fake_loss - real_loss).\n",
    "# We will add the gradient penalty later to this loss function.\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "\n",
    "# Set the number of epochs for trainining.\n",
    "epochs = 60\n",
    "\n",
    "# Instantiate the customer `GANMonitor` Keras callback.\n",
    "cbk = GANMonitor(num_img=3, latent_dim=noise_dim)\n",
    "\n",
    "# Instantiate the WGAN model.\n",
    "wgan = WGAN(\n",
    "    discriminator=d_model,\n",
    "    generator=g_model,\n",
    "    latent_dim=noise_dim,\n",
    "    discriminator_extra_steps=3,\n",
    ")\n",
    "\n",
    "# Compile the WGAN model.\n",
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n",
    "\n",
    "# Start training the model.\n",
    "history = wgan.fit(X, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instructional-childhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7febdc17ea00>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['d_loss'])\n",
    "plt.plot(history.history['g_loss'],'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
