{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atlantic-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X,y_hr,y_participant,y_activity = pickle.load(open('../data/heart_rate_tabular_data_ppg_dalia.p','rb'))\n",
    "activity_dict1 = {'No Label':-1,'Sitting':0,'Stairs':1,'Soccer':2,\n",
    "                'Cycling':3,'Driving':4,'Lunch':-1,'Walking':5,\n",
    "                'Working':-1}\n",
    "X = X[:,:,1:].reshape(-1,3,256)\n",
    "y_activity = np.array([activity_dict1[a] for a in y_activity])\n",
    "y_activity = OneHotEncoder().fit_transform(y_activity.reshape(-1,1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fiscal-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "from torchsummary import summary\n",
    "import pylab as plt\n",
    "batch_size = 100\n",
    "n_epochs = 300\n",
    "n_classes = 6\n",
    "latent_size = 100\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bottom-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "tensor_x = torch.Tensor(X) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(y_activity)\n",
    "dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    def __init__(self, num_classes=6,in_channels=3,\n",
    "                 out_channels = [50,100,200,50],kernel_size=10,\n",
    "                 pool_size=2):\n",
    "        super(D, self).__init__()\n",
    "        self.ngpu = torch.cuda.device_count()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # Convolution 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(self.in_channels,self.out_channels[0], kernel_size, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2, inplace=False),\n",
    "            nn.MaxPool1d(pool_size*2,pool_size,1)\n",
    "        )\n",
    "        # Convolution 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(self.out_channels[0],self.out_channels[1],kernel_size, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2, inplace=False),\n",
    "            nn.MaxPool1d(pool_size*2,pool_size,1)\n",
    "        )\n",
    "        # Convolution 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(self.out_channels[1],self.out_channels[2],kernel_size, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2, inplace=False),\n",
    "            nn.MaxPool1d(pool_size*2,pool_size,1)\n",
    "        )\n",
    "        # Convolution 4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(self.out_channels[2],self.out_channels[3],kernel_size, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.2, inplace=False),\n",
    "            nn.MaxPool1d(pool_size*2,pool_size,1)\n",
    "        )\n",
    "        \n",
    "        self.flattten = nn.Flatten()\n",
    "        self.discriminatior_output = nn.Sequential(\n",
    "            nn.Linear(450,200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,1),\n",
    "            nn.Sigmoid()            \n",
    "        )\n",
    "        self.auxillary_output = nn.Sequential(\n",
    "            nn.Linear(450,200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,num_classes),\n",
    "            nn.Softmax()           \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        data = self.conv1(data)\n",
    "        data = self.conv2(data)\n",
    "        data = self.conv3(data)\n",
    "        data = self.conv4(data)\n",
    "        data = self.flattten(data)\n",
    "        real_fake = self.discriminatior_output(data).view(-1, 1).squeeze(1)\n",
    "        classes = self.auxillary_output(data)\n",
    "            \n",
    "        return real_fake,classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broadband-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self,\n",
    "                 latent_size = 100,\n",
    "                 num_classes = 6,\n",
    "                 out_channels = 3,\n",
    "                 out_timesteps = 256):\n",
    "        super(G, self).__init__()\n",
    "        self.ngpu = torch.cuda.device_count()\n",
    "        self.latent_size = latent_size\n",
    "        self.out_channels = out_channels\n",
    "        self.out_timesteps = out_timesteps\n",
    "        self.latent_size = latent_size\n",
    "        self.num_classes = num_classes\n",
    "        self.label_to_noise = nn.Sequential(\n",
    "            nn.Linear(self.num_classes,self.latent_size//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.latent_size//4,self.latent_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.latent_size//2,self.latent_size)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_network = nn.Sequential(\n",
    "            nn.Linear(self.latent_size*2,self.latent_size*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.latent_size*4,self.latent_size*8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.latent_size*8,self.out_channels*self.out_timesteps)            \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, labels,noise):\n",
    "        labels = labels.view(-1,self.num_classes)\n",
    "        noise1 = self.label_to_noise(labels).view(-1,self.latent_size,1)\n",
    "        noise = noise.view(-1,self.latent_size,1)\n",
    "        noise = torch.cat((noise,noise1),-1).view(-1,self.latent_size,2)\n",
    "        noise = self.flatten(noise)\n",
    "        noise = self.dense_network(noise).view(-1,self.out_channels,self.out_timesteps)\n",
    "        print(noise.shape)\n",
    "        return noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parliamentary-worship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 25]             175\n",
      "              ReLU-2                   [-1, 25]               0\n",
      "            Linear-3                   [-1, 50]           1,300\n",
      "              ReLU-4                   [-1, 50]               0\n",
      "            Linear-5                  [-1, 100]           5,100\n",
      "           Flatten-6                  [-1, 200]               0\n",
      "            Linear-7                  [-1, 400]          80,400\n",
      "              ReLU-8                  [-1, 400]               0\n",
      "            Linear-9                  [-1, 800]         320,800\n",
      "             Tanh-10                  [-1, 800]               0\n",
      "           Linear-11                  [-1, 768]         615,168\n",
      "================================================================\n",
      "Total params: 1,022,943\n",
      "Trainable params: 1,022,943\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 3.90\n",
      "Estimated Total Size (MB): 3.93\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 50, 249]           1,500\n",
      "         LeakyReLU-2              [-1, 50, 249]               0\n",
      "           Dropout-3              [-1, 50, 249]               0\n",
      "         MaxPool1d-4              [-1, 50, 124]               0\n",
      "            Conv1d-5             [-1, 100, 117]          50,000\n",
      "         LeakyReLU-6             [-1, 100, 117]               0\n",
      "           Dropout-7             [-1, 100, 117]               0\n",
      "         MaxPool1d-8              [-1, 100, 58]               0\n",
      "            Conv1d-9              [-1, 200, 51]         200,000\n",
      "        LeakyReLU-10              [-1, 200, 51]               0\n",
      "          Dropout-11              [-1, 200, 51]               0\n",
      "        MaxPool1d-12              [-1, 200, 25]               0\n",
      "           Conv1d-13               [-1, 50, 18]         100,000\n",
      "        LeakyReLU-14               [-1, 50, 18]               0\n",
      "          Dropout-15               [-1, 50, 18]               0\n",
      "        MaxPool1d-16                [-1, 50, 9]               0\n",
      "          Flatten-17                  [-1, 450]               0\n",
      "           Linear-18                  [-1, 200]          90,200\n",
      "             ReLU-19                  [-1, 200]               0\n",
      "           Linear-20                   [-1, 20]           4,020\n",
      "             ReLU-21                   [-1, 20]               0\n",
      "           Linear-22                    [-1, 1]              21\n",
      "          Sigmoid-23                    [-1, 1]               0\n",
      "           Linear-24                  [-1, 200]          90,200\n",
      "             ReLU-25                  [-1, 200]               0\n",
      "           Linear-26                   [-1, 20]           4,020\n",
      "             ReLU-27                   [-1, 20]               0\n",
      "           Linear-28                    [-1, 6]             126\n",
      "          Softmax-29                    [-1, 6]               0\n",
      "================================================================\n",
      "Total params: 540,087\n",
      "Trainable params: 540,087\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.95\n",
      "Params size (MB): 2.06\n",
      "Estimated Total Size (MB): 3.01\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azim/miniconda3/envs/test1/lib/python3.8/site-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "dmodel = D().to(device)\n",
    "gmodel = G().to(device)\n",
    "data_noise = torch.empty(batch_size, latent_size, device=device)\n",
    "print(summary(gmodel,[(1,6),(1,100)]))\n",
    "print(summary(dmodel,(3,256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "continuing-threshold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1694,  2.9595, -0.3093,  ..., -1.3859,  0.5841,  0.4916],\n",
       "        [ 0.7396, -0.9584,  1.1998,  ..., -0.3093, -0.9942, -0.4272],\n",
       "        [-0.1712,  0.5136, -1.0470,  ..., -0.0748,  0.8148, -1.1461],\n",
       "        ...,\n",
       "        [ 0.0120, -0.0710,  0.5479,  ..., -0.9409, -0.3572,  0.8597],\n",
       "        [-0.6438,  0.4561, -0.1333,  ...,  0.6987,  0.8947, -3.7530],\n",
       "        [ 2.0791, -0.4679,  1.6314,  ...,  1.2703, -1.3746, -1.6066]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-planner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
