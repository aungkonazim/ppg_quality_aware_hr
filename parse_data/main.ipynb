{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzipping Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WESAD.zip']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory = '../../ppg_quality_aware_hr/data/WESAD.zip'\n",
    "output_directory = '../../ppg_quality_aware_hr/data/'\n",
    "\n",
    "if not os.path.isdir(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "print(os.listdir(output_directory))\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(directory, 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Individual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ecgdetectors import Detectors\n",
    "from scipy import signal\n",
    "from scipy.stats import skew,kurtosis,iqr\n",
    "import pickle\n",
    "from peak_valley import compute_peak_valley\n",
    "from respiration_feature import rip_cycle_feature_computation\n",
    "filelists = ['../../ppg_quality_aware_hr/data/WESAD/'+a+'/'+a+'.pkl' for a in os.listdir('../../ppg_quality_aware_hr/data/WESAD/') if a[-1] not in ['s','f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   4 out of  15 | elapsed:  7.3min remaining: 20.0min\n",
      "[Parallel(n_jobs=10)]: Done  12 out of  15 | elapsed: 14.6min remaining:  3.7min\n",
      "[Parallel(n_jobs=10)]: Done  15 out of  15 | elapsed: 16.3min finished\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "def get_ecg_rr(ecg_data):\n",
    "    detectors = Detectors(700)\n",
    "    rpeaks = detectors.hamilton_detector(ecg_data[:,1])\n",
    "    ecg_r_ts = ecg_data[np.array(rpeaks),0]\n",
    "    ecg_rr_ts = ecg_r_ts[1:]\n",
    "    ecg_rr_sample = np.diff(ecg_r_ts)\n",
    "    ecg_rr = pd.DataFrame(np.vstack([ecg_rr_ts,ecg_rr_sample]).T,columns=['time','rr'])\n",
    "    ecg_rr['timestamp'] = ecg_rr['time'].apply(lambda a:datetime.utcfromtimestamp(a))\n",
    "    return ecg_rr\n",
    "\n",
    "def bandpass_filter_ppg(data,Fs=64,fil_type='ppg'):\n",
    "    X0 = data[:,1]\n",
    "    X1 = signal.detrend(X0,axis=0,type='constant')\n",
    "    X2 = np.zeros((np.shape(X1)[0],data.shape[1]))\n",
    "    nyq = Fs/2\n",
    "    b = signal.firls(219,np.array([0,0.3,0.5,3,3.5,nyq]),\n",
    "                              np.array([0,0,1,1,0,0]),np.array([10,1,1]),fs=nyq*2)\n",
    "    a = [1]\n",
    "    X2[:,0] = data[:,0]\n",
    "    X2[:,1] = signal.filtfilt(b, a, X1)\n",
    "    return X2\n",
    "\n",
    "def bandpass_filter_respiration(data,Fs=700,fil_type='ppg'):\n",
    "    X0 = data[:,1]\n",
    "    X1 = signal.detrend(X0,axis=0,type='constant')\n",
    "    X2 = np.zeros((np.shape(X1)[0],data.shape[1]))\n",
    "    nyq = Fs/2\n",
    "    b = signal.firls(219,np.array([0,0.02,0.05,1,1.5,nyq]),\n",
    "                              np.array([0,0,1,1,0,0]),np.array([10,1,1]),fs=nyq*2)\n",
    "    a = [1]\n",
    "    X2[:,0] = data[:,0]\n",
    "    X2[:,1] = signal.filtfilt(b, a, X1)\n",
    "    return X2\n",
    "\n",
    "def get_quality_features(ppg_data,ppg_fs=64,window_size=2.5):\n",
    "    ppg_data_final = []\n",
    "    n = int(ppg_fs*window_size/2)\n",
    "    for i in range(n,ppg_data.shape[0]-n,1):\n",
    "        tmp = []\n",
    "        tmp.append(ppg_data[i,0])\n",
    "        tmp.append(ppg_data[i,1])\n",
    "        sample = ppg_data[(i-n):(i+n),1]\n",
    "        tmp.append(skew(sample))\n",
    "        tmp.append(kurtosis(sample))\n",
    "        tmp.append(iqr(sample))\n",
    "        f,pxx = signal.welch(sample,fs=ppg_fs,nperseg=len(sample)//2,nfft=10000,axis=0)\n",
    "        tmp.append(np.trapz(pxx[np.where((f>=.8)&(f<=2.5))[0]])/np.trapz(pxx))\n",
    "        ppg_data_final.append(np.array(tmp))\n",
    "    return np.array(ppg_data_final)\n",
    "\n",
    "\n",
    "def save_participant_data(filename,ecg_fs = 700,ppg_fs = 64,acc_fs=32,window_size=8):\n",
    "    data = pickle.load(open(filename,'rb'),encoding='latin1')\n",
    "    ppg_data = data['signal']['wrist']['BVP']\n",
    "    acc_data = data['signal']['wrist']['ACC']/64\n",
    "    ecg_data = data['signal']['chest']['ECG']\n",
    "    respiration_data = data['signal']['chest']['Resp']\n",
    "    total_seconds = ppg_data.shape[0]/ppg_fs\n",
    "    start_ts = datetime.utcnow().timestamp()\n",
    "    ecg_ts = start_ts + np.arange(0,total_seconds,1/ecg_fs)\n",
    "    acc_ts = start_ts + np.arange(0,total_seconds,1/acc_fs)\n",
    "    acc_data = np.concatenate([acc_ts.reshape(-1,1),acc_data],axis=1)\n",
    "    respiration_ts = ecg_ts\n",
    "    respiration_data = np.vstack([respiration_ts,respiration_data.reshape(-1)]).T\n",
    "    ecg_data = np.vstack([ecg_ts,ecg_data.reshape(-1)]).T\n",
    "    ecg_rr1 = get_ecg_rr(ecg_data)\n",
    "    ecg_rr = ecg_rr1.values\n",
    "    ppg_ts = start_ts + np.arange(0,total_seconds,1/ppg_fs)\n",
    "    ppg_data = np.vstack([ppg_ts,ppg_data.reshape(-1)]).T\n",
    "#     ppg_data = bandpass_filter_ppg(ppg_data,Fs=ppg_fs,fil_type='ppg')\n",
    "#     plt.figure()\n",
    "#     plt.plot(respiration_data[:,0],respiration_data[:,1])\n",
    "    respiration_data = bandpass_filter_respiration(respiration_data,Fs=ecg_fs,fil_type='ppg')\n",
    "#     plt.plot(respiration_data[:,0],respiration_data[:,1])\n",
    "#     plt.show()\n",
    "#     return 0\n",
    "    respiration_data[:,0] = respiration_data[:,0]*1000\n",
    "    peak_index,valley_index = compute_peak_valley(respiration_data)\n",
    "    peak_data = respiration_data[peak_index]\n",
    "    valley_data = respiration_data[valley_index]\n",
    "    rip_feature = rip_cycle_feature_computation(peak_data,valley_data)[:,:5]\n",
    "    rip_feature[:,:2] = rip_feature[:,:2]/1000\n",
    "    ppg_data = get_quality_features(ppg_data)\n",
    "    ppg_data = pd.DataFrame(ppg_data,columns=['time','ppg','skew','kurtosis','iqr','relative_power']).dropna().sort_values('time').reset_index(drop=True)\n",
    "#     ppg_data['timestamp'] = ppg_data['time'].apply(lambda a:datetime.utcfromtimestamp(a))\n",
    "    respiration_data[:,0] = respiration_data[:,0]/1000\n",
    "    all_data = []\n",
    "    for i in range(0,ppg_data.shape[0]-window_size*ppg_fs,window_size*ppg_fs//4):\n",
    "        a = ppg_data.loc[i:i+window_size*ppg_fs-1]\n",
    "        b = respiration_data[np.where((respiration_data[:,0]>=a['time'].min())&(respiration_data[:,0]<a['time'].max()))[0],1].reshape(-1,1)\n",
    "        all_data.append([a['time'].min(),a['time'].max(),\n",
    "                         a[['time','ppg','skew','kurtosis','iqr','relative_power']].sort_values('time').reset_index(drop=True),b])\n",
    "    \n",
    "    ppg_windows = pd.DataFrame(all_data,columns=['start_time','end_time','data','respiration'])\n",
    "    ppg_windows['ecg_rr'] = ppg_windows.apply(lambda a:np.mean(ecg_rr[np.where((ecg_rr[:,0]>=a['start_time'])&(ecg_rr[:,0]<a['end_time']))[0],1]),axis=1)\n",
    "    ppg_windows['inspiration_duration'] = ppg_windows.apply(lambda a:np.mean(rip_feature[np.where((rip_feature[:,1]>=a['start_time'])&(rip_feature[:,0]<a['end_time']))[0],2]),axis=1)\n",
    "    ppg_windows['expiration_duration'] = ppg_windows.apply(lambda a:np.mean(rip_feature[np.where((rip_feature[:,1]>=a['start_time'])&(rip_feature[:,0]<a['end_time']))[0],3]),axis=1)\n",
    "    ppg_windows['respiration_duration'] = ppg_windows.apply(lambda a:np.mean(rip_feature[np.where((rip_feature[:,1]>=a['start_time'])&(rip_feature[:,0]<a['end_time']))[0],4]),axis=1)\n",
    "    ppg_windows['acc_window'] = ppg_windows.apply(lambda a: acc_data[np.where((acc_data[:,0]>=a['start_time'])&(acc_data[:,0]<a['end_time']))[0],:],axis=1)\n",
    "    print(ppg_windows.shape,ppg_windows.dropna().shape)\n",
    "    print(ppg_windows.shape)\n",
    "    if not os.path.isdir(output_directory+str(window_size)):\n",
    "        os.makedirs(output_directory+str(window_size))\n",
    "    final_path = output_directory+str(window_size)+'/'\n",
    "    participant_name = filename.split('/')[-1]\n",
    "    pickle.dump(ppg_windows,open(final_path+participant_name,'wb'))\n",
    "    return ppg_windows\n",
    "\n",
    "from joblib import Parallel,delayed\n",
    "output_directory = '../../ppg_quality_aware_hr/data/'\n",
    "final = Parallel(n_jobs=10,verbose=2)(delayed(save_participant_data)(f,window_size=8) for f in filelists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelists = ['../../ppg_quality_aware_hr/data/8/'+a for a in os.listdir('../../ppg_quality_aware_hr/data/8/') if a[-1] not in ['s','f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n",
      "[512]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filelists)):\n",
    "    data = pickle.load(open(filelists[i],'rb'))\n",
    "#     data['acc_window'] = data['acc_window'].apply(lambda a:a[:255])\n",
    "    data['shape'] = data['data'].apply(lambda a:a.shape[0])\n",
    "    print(data['shape'].unique())\n",
    "\n",
    "#     plt.hist(data['data'].loc[0]['relative_power'])\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
