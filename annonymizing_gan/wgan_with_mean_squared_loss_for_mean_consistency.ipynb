{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wired-elder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25144, 256, 4)\n",
      "(25144, 256, 3)\n",
      "(4696, 256, 3)\n",
      "(4696, 256, 3)\n",
      "(4696, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "def conv_block(x,filters,activation,kernel_size=(3, 3),strides=(1, 1),\n",
    "               padding=\"same\",use_bias=True,use_bn=False,\n",
    "               use_dropout=False,drop_value=0.5):\n",
    "    \n",
    "    x = layers.Conv1D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias)(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_discriminator_model(input_shape = (256,3)):\n",
    "    \n",
    "    input_ = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = conv_block(input_,64,kernel_size=20,strides=2,use_bn=False,use_bias=True,\n",
    "        activation=layers.LeakyReLU(0.2),use_dropout=False,drop_value=0.3)\n",
    "    \n",
    "    x = conv_block(x,128,kernel_size=10,strides=2,use_bn=False,activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,use_dropout=True,drop_value=0.3)\n",
    "    \n",
    "    x = conv_block(x,128,kernel_size=10,strides=2,use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),use_bias=True,use_dropout=True,drop_value=0.3)\n",
    "    \n",
    "    x = conv_block(x,128,kernel_size=10,strides=2,use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),use_bias=True,use_dropout=True,drop_value=0.3)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = layers.Dense(1)(x)\n",
    "\n",
    "    d_model = keras.models.Model(input_, x, name=\"discriminator\")\n",
    "    \n",
    "    return d_model\n",
    "def upsample_block(x,filters,activation,kernel_size=20, strides=1, up_size=2, \n",
    "                    padding=\"same\",use_bn=False,use_bias=True,\n",
    "                    use_dropout=False,drop_value=0.3):\n",
    "    \n",
    "    x = layers.UpSampling1D(up_size)(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias)(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "        \n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_generator_model(latent_size=100,first_dense_shape=128,mean_image_shape=256):\n",
    "    noise = layers.Input(shape=(latent_size,))\n",
    "    mean_ts = layers.Input(shape=(mean_image_shape,3))\n",
    "    x = layers.Dense(first_dense_shape, use_bias=False)(noise)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Reshape((128,1))(x)\n",
    "    \n",
    "    x = upsample_block(x,128, layers.LeakyReLU(0.2), strides=1, use_bias=False,\n",
    "                       use_bn=True, padding=\"same\", use_dropout=False)\n",
    "    \n",
    "    mean_ts1 = conv_block(mean_ts,64,kernel_size=40,strides=1,use_bn=False,use_bias=True,\n",
    "                   activation=layers.LeakyReLU(0.2),use_dropout=False,drop_value=0.3)\n",
    "    \n",
    "    x = layers.Concatenate(axis=2)([x,mean_ts1])\n",
    "    \n",
    "    x = upsample_block(x, 64, layers.LeakyReLU(0.2), strides=1, use_bias=False,\n",
    "                       use_bn=False, padding=\"same\", use_dropout=False)\n",
    "    \n",
    "    x = conv_block(x,64,kernel_size=40,strides=2,use_bn=False,use_bias=True,\n",
    "                   activation=layers.LeakyReLU(0.2),use_dropout=False,drop_value=0.3)\n",
    "    \n",
    "    x = conv_block(x,3,kernel_size=20,strides=1,use_bn=False,use_bias=True,\n",
    "                  activation=layers.Activation('tanh'),use_dropout=False,drop_value=0.3)\n",
    "    \n",
    "    g_model = keras.models.Model([noise,mean_ts], x, name=\"generator\")\n",
    "    \n",
    "    \n",
    "    return g_model\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# for p in range(1):\n",
    "p = 0\n",
    "X,y_hr,y_participant,y_activity,y_time = pickle.load(open('../data/heart_rate_tabular_data_ppg_dalia.p','rb'))\n",
    "print(X.shape)\n",
    "activity_dict1 = {'No Label':-1,'Sitting':0,'Stairs':1,'Soccer':2,\n",
    "                'Cycling':3,'Driving':4,'Lunch':-1,'Walking':5,\n",
    "                'Working':-1}\n",
    "y_activity = np.array([activity_dict1[a] for a in y_activity])\n",
    "X = X[:,:,1:].reshape(-1,256,3)\n",
    "print(X.shape)\n",
    "act_value = 5\n",
    "X = X[np.where(y_activity==act_value)[0]]\n",
    "print(X.shape)\n",
    "min1,max1 = np.min(X),np.max(X)\n",
    "cc = np.max(np.abs(X))\n",
    "X = X/cc\n",
    "k = 1\n",
    "print(X.shape)\n",
    "arrays = np.array_split(X,k,axis=1)\n",
    "print(X.shape)\n",
    "X1 = []\n",
    "for a in arrays:\n",
    "    X1.append(np.concatenate([np.mean(a,axis=1).reshape(a.shape[0],-1,a.shape[2])]*a.shape[1],axis=1))\n",
    "X1 = np.concatenate(X1,axis=1)\n",
    "BATCH_SIZE = 200\n",
    "batch_size = BATCH_SIZE\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X,X1)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heated-caution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4696, 256, 3), (4696, 256, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generic-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(batch_size, real_images, fake_images,discriminator):\n",
    "    \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "    This loss is calculated on an interpolated image\n",
    "    and added to the discriminator loss.\n",
    "    \"\"\"\n",
    "    # Get the interpolated image\n",
    "    alpha = tf.random.normal([batch_size, 1, 1], 0.0, 1.0)\n",
    "    fake_images = tf.cast(fake_images,tf.float32)\n",
    "    real_images = tf.cast(real_images,tf.float32)\n",
    "#     print(fake_images.shape,real_images.shape)\n",
    "    diff = fake_images - real_images\n",
    "    interpolated = real_images + alpha * diff\n",
    "#     print(interpolated)\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        # 1. Get the discriminator output for this interpolated image.\n",
    "        pred = discriminator(interpolated, training=True)\n",
    "\n",
    "    # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    # 3. Calculate the norm of the gradients.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp\n",
    "\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return -real_loss +fake_loss\n",
    "\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "joined-attachment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          12800       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128)          512         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 128)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128, 1)       0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d (UpSampling1D)    (None, 256, 1)       0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 256, 128)     2560        up_sampling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 256, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 128)     512         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 256, 64)      7744        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 256, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 256, 64)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 192)     0           leaky_re_lu_1[0][0]              \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 512, 192)     0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 512, 64)      245760      up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 512, 64)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 256, 64)      163904      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 256, 64)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 256, 3)       3843        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 3)       0           conv1d_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 437,635\n",
      "Trainable params: 437,123\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 3)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 128, 64)           3904      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 64, 128)           82048     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 32, 128)           163968    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16, 128)           163968    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 415,937\n",
      "Trainable params: 415,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "noise_dim = 100\n",
    "BATCH_SIZE = 200\n",
    "epochs = 60\n",
    "d_steps = 5\n",
    "latent_dim = noise_dim\n",
    "gp_weight = 10\n",
    "\n",
    "g_model = get_generator_model()\n",
    "g_model.summary()\n",
    "d_model = get_discriminator_model(input_shape=(256,3))\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "difficult-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "generator_optimizer = keras.optimizers.RMSprop(\n",
    "    learning_rate=0.0002)\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "    learning_rate=0.0002)\n",
    "\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return -real_loss +fake_loss\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "activity_estimator = load_model('../model_files/activity_estimator_8_secs_dalia.hdf5')\n",
    "for k in range(epochs):\n",
    "    for i,real_images in enumerate(dataset):\n",
    "        mean_images = real_images[1]\n",
    "        real_images = real_images[0]\n",
    "        batch_size = mean_images.shape[0]\n",
    "        for i in range(d_steps):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = g_model([random_latent_vectors,mean_images], training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = d_model(fake_images, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = d_model(real_images, training=True)\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = discriminator_loss(real_img=real_logits, fake_img=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = gradient_penalty(batch_size, real_images, fake_images,discriminator=d_model)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, d_model.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            discriminator_optimizer.apply_gradients(zip(d_gradient, d_model.trainable_variables))\n",
    "        \n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "        y_walking = tf.zeros((batch_size))+act_value\n",
    "        activity_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = g_model([random_latent_vectors,mean_images], training=True)\n",
    "            gen_img_logits = d_model(generated_images, training=True)\n",
    "            generated_mean = tf.concat([tf.reshape(tf.reduce_mean(generated_images,axis=1),\n",
    "                                                   (generated_images.shape[0],-1,generated_images.shape[2]))]*generated_images.shape[1],axis=1)\n",
    "            \n",
    "            generated_activity = activity_estimator(generated_images*cc,training=True)\n",
    "            g_loss = generator_loss(gen_img_logits) + tf.reduce_mean(tf.keras.losses.mean_squared_error(mean_images,generated_mean))\n",
    "            g_loss = g_loss+ activity_loss(y_walking.numpy(),generated_activity.numpy())\n",
    "        gen_gradient = tape.gradient(g_loss, g_model.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(gen_gradient, g_model.trainable_variables))\n",
    "    \n",
    "    g_model.save('./walking_generator_epoch_/'+str(k)+'.hdf5')\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    \n",
    "    generated_images_numpy = generated_images.numpy()\n",
    "    generated_images = g_model([random_latent_vectors,mean_images], training=True)\n",
    "    plt.figure()\n",
    "    img = generated_images_numpy[0]*cc*64\n",
    "    mean_img = mean_images.numpy()[0]*cc*64\n",
    "    plt.plot(img)\n",
    "    plt.plot(mean_img,'--')\n",
    "    plt.ylim([min1*64,max1*64])\n",
    "    plt.savefig(\"./images/generated_img_{i}.png\".format(i=k))\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fixed-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y_hr,y_participant,y_activity,y_time = pickle.load(open('../data/heart_rate_tabular_data_ppg_dalia.p','rb'))\n",
    "activity_dict1 = {'No Label':-1,'Sitting':0,'Stairs':1,'Soccer':2,\n",
    "                'Cycling':3,'Driving':4,'Lunch':-1,'Walking':5,\n",
    "                'Working':-1}\n",
    "y_activity = np.array([activity_dict1[a] for a in y_activity])\n",
    "X = X[:,:,1:].reshape(-1,256,3)\n",
    "act_value = 5\n",
    "X = X[np.where(y_activity==act_value)[0]]\n",
    "min1,max1 = np.min(X),np.max(X)\n",
    "cc = np.max(np.abs(X))\n",
    "X = X/cc\n",
    "k = 1\n",
    "arrays = np.array_split(X,k,axis=1)\n",
    "X1 = []\n",
    "for a in arrays:\n",
    "    X1.append(np.concatenate([np.mean(a,axis=1).reshape(a.shape[0],-1,a.shape[2])]*a.shape[1],axis=1))\n",
    "X1 = np.concatenate(X1,axis=1)\n",
    "y_participant = y_participant[np.where(y_activity==act_value)[0]]\n",
    "y_activity = y_activity[np.where(y_activity==act_value)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparable-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=600\n",
    "plt.plot(X[i]*cc*64)\n",
    "plt.plot(X1[i]*cc*64,'--')\n",
    "plt.ylim([min1*64,max1*64])\n",
    "plt.savefig(\"./images/real_img_{i}.png\".format(i=i))\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "common-skiing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9009795570698467 original 0.06601362862010221 GAN activity_original 0.9546422487223168 activity_pred 0.09646507666098808\n",
      "0.9009795570698467 original 0.22040034071550255 GAN activity_original 0.9546422487223168 activity_pred 0.2989778534923339\n",
      "0.9009795570698467 original 0.06494889267461669 GAN activity_original 0.9546422487223168 activity_pred 0.17802385008517888\n",
      "0.9009795570698467 original 0.12436115843270869 GAN activity_original 0.9546422487223168 activity_pred 0.2604344122657581\n",
      "0.9009795570698467 original 0.06643952299829642 GAN activity_original 0.9546422487223168 activity_pred 0.09369676320272573\n",
      "0.9009795570698467 original 0.20826235093696763 GAN activity_original 0.9546422487223168 activity_pred 0.3494463373083475\n",
      "0.9009795570698467 original 0.06750425894378194 GAN activity_original 0.9546422487223168 activity_pred 0.0\n",
      "0.9009795570698467 original 0.15502555366269166 GAN activity_original 0.9546422487223168 activity_pred 0.6220187393526405\n",
      "0.9009795570698467 original 0.13820272572402045 GAN activity_original 0.9546422487223168 activity_pred 0.15438671209540034\n",
      "0.9009795570698467 original 0.18356047700170358 GAN activity_original 0.9546422487223168 activity_pred 0.385221465076661\n",
      "0.9009795570698467 original 0.19080068143100512 GAN activity_original 0.9546422487223168 activity_pred 0.2389267461669506\n",
      "0.9009795570698467 original 0.09689097103918229 GAN activity_original 0.9546422487223168 activity_pred 0.13990630323679729\n",
      "0.9009795570698467 original 0.05643100511073254 GAN activity_original 0.9546422487223168 activity_pred 0.22636286201022146\n",
      "0.9009795570698467 original 0.06729131175468483 GAN activity_original 0.9546422487223168 activity_pred 0.227427597955707\n",
      "0.9009795570698467 original 0.047913117546848384 GAN activity_original 0.9546422487223168 activity_pred 0.12457410562180579\n",
      "0.9009795570698467 original 0.178236797274276 GAN activity_original 0.9546422487223168 activity_pred 0.19484667802385008\n",
      "0.9009795570698467 original 0.15374787052810904 GAN activity_original 0.9546422487223168 activity_pred 0.4891396933560477\n",
      "0.9009795570698467 original 0.13266609880749575 GAN activity_original 0.9546422487223168 activity_pred 0.28492333901192507\n",
      "0.9009795570698467 original 0.168015332197615 GAN activity_original 0.9546422487223168 activity_pred 0.3481686541737649\n",
      "0.9009795570698467 original 0.21550255536626917 GAN activity_original 0.9546422487223168 activity_pred 0.3515758091993186\n",
      "0.9009795570698467 original 0.1201022146507666 GAN activity_original 0.9546422487223168 activity_pred 0.18079216354344121\n",
      "0.9009795570698467 original 0.07964224872231687 GAN activity_original 0.9546422487223168 activity_pred 0.16205281090289608\n",
      "0.9009795570698467 original 0.11669505962521294 GAN activity_original 0.9546422487223168 activity_pred 0.11243611584327087\n",
      "0.9009795570698467 original 0.21081771720613288 GAN activity_original 0.9546422487223168 activity_pred 0.3349659284497445\n",
      "0.9009795570698467 original 0.16482112436115842 GAN activity_original 0.9546422487223168 activity_pred 0.4080068143100511\n",
      "0.9009795570698467 original 0.18611584327086883 GAN activity_original 0.9546422487223168 activity_pred 0.30132027257240207\n",
      "0.9009795570698467 original 0.17482964224872233 GAN activity_original 0.9546422487223168 activity_pred 0.4024701873935264\n",
      "0.9009795570698467 original 0.17078364565587734 GAN activity_original 0.9546422487223168 activity_pred 0.360732538330494\n",
      "0.9009795570698467 original 0.20826235093696763 GAN activity_original 0.9546422487223168 activity_pred 0.23509369676320271\n",
      "0.9009795570698467 original 0.17674616695059625 GAN activity_original 0.9546422487223168 activity_pred 0.348381601362862\n",
      "0.9009795570698467 original 0.07240204429301533 GAN activity_original 0.9546422487223168 activity_pred 0.13990630323679729\n",
      "0.9009795570698467 original 0.15438671209540034 GAN activity_original 0.9546422487223168 activity_pred 0.32112436115843274\n",
      "0.9009795570698467 original 0.2059199318568995 GAN activity_original 0.9546422487223168 activity_pred 0.20272572402044292\n",
      "0.9009795570698467 original 0.1471465076660988 GAN activity_original 0.9546422487223168 activity_pred 0.32431856899488926\n",
      "0.9009795570698467 original 0.09178023850085179 GAN activity_original 0.9546422487223168 activity_pred 0.12031516183986371\n",
      "0.9009795570698467 original 0.16162691652470187 GAN activity_original 0.9546422487223168 activity_pred 0.39416524701873934\n",
      "0.9009795570698467 original 0.1575809199318569 GAN activity_original 0.9546422487223168 activity_pred 0.3023850085178876\n",
      "0.9009795570698467 original 0.15055366269165246 GAN activity_original 0.9546422487223168 activity_pred 0.13969335604770017\n",
      "0.9009795570698467 original 0.24084327086882454 GAN activity_original 0.9546422487223168 activity_pred 0.34667802385008517\n",
      "0.9009795570698467 original 0.20166098807495741 GAN activity_original 0.9546422487223168 activity_pred 0.3390119250425894\n",
      "0.9009795570698467 original 0.14246166950596253 GAN activity_original 0.9546422487223168 activity_pred 0.5485519591141397\n",
      "0.9009795570698467 original 0.0434412265758092 GAN activity_original 0.9546422487223168 activity_pred 0.06793015332197615\n",
      "0.9009795570698467 original 0.22103918228279387 GAN activity_original 0.9546422487223168 activity_pred 0.4341993185689949\n",
      "0.9009795570698467 original 0.14352640545144804 GAN activity_original 0.9546422487223168 activity_pred 0.15971039182282795\n",
      "0.9009795570698467 original 0.12095400340715502 GAN activity_original 0.9546422487223168 activity_pred 0.16929301533219762\n",
      "0.9009795570698467 original 0.13905451448040887 GAN activity_original 0.9546422487223168 activity_pred 0.1903747870528109\n",
      "0.9009795570698467 original 0.13969335604770017 GAN activity_original 0.9546422487223168 activity_pred 0.25255536626916525\n",
      "0.9009795570698467 original 0.19207836456558774 GAN activity_original 0.9546422487223168 activity_pred 0.49126916524701875\n",
      "0.9009795570698467 original 0.053023850085178875 GAN activity_original 0.9546422487223168 activity_pred 0.17291311754684838\n",
      "0.9009795570698467 original 0.15694207836456558 GAN activity_original 0.9546422487223168 activity_pred 0.14927597955706984\n",
      "0.9009795570698467 original 0.056218057921635436 GAN activity_original 0.9546422487223168 activity_pred 0.1575809199318569\n",
      "0.9009795570698467 original 0.046848381601362864 GAN activity_original 0.9546422487223168 activity_pred 0.09689097103918229\n",
      "0.9009795570698467 original 0.16375638841567292 GAN activity_original 0.9546422487223168 activity_pred 0.25149063032367974\n",
      "0.9009795570698467 original 0.1303236797274276 GAN activity_original 0.9546422487223168 activity_pred 0.256175468483816\n",
      "0.9009795570698467 original 0.0704855195911414 GAN activity_original 0.9546422487223168 activity_pred 0.00021294718909710392\n",
      "0.9009795570698467 original 0.1675894378194208 GAN activity_original 0.9546422487223168 activity_pred 0.25979557069846676\n",
      "0.9009795570698467 original 0.12414821124361158 GAN activity_original 0.9546422487223168 activity_pred 0.22614991482112437\n",
      "0.9009795570698467 original 0.0873083475298126 GAN activity_original 0.9546422487223168 activity_pred 0.0975298126064736\n",
      "0.9009795570698467 original 0.1895229982964225 GAN activity_original 0.9546422487223168 activity_pred 0.303236797274276\n",
      "0.9009795570698467 original 0.17546848381601363 GAN activity_original 0.9546422487223168 activity_pred 0.2938671209540034\n"
     ]
    }
   ],
   "source": [
    "path = './walking_generator_epoch_/'\n",
    "for f in os.listdir(path):\n",
    "    g_model = load_model(path+f)\n",
    "    random_latent_vectors = tf.random.normal(shape=(X.shape[0], latent_dim))\n",
    "    generated_X = g_model([random_latent_vectors,X1], training=False)\n",
    "\n",
    "\n",
    "    model = load_model('../model_files/person_estimator_8_secs_dalia_final.hdf5')\n",
    "\n",
    "    # model.summary()\n",
    "    y_pred_original = model.predict(X*cc).argmax(axis=1)\n",
    "    y_pred_gan = model.predict(generated_X*cc).argmax(axis=1)\n",
    "\n",
    "\n",
    "    \n",
    "    activity_estimator = load_model('../model_files/activity_estimator_8_secs_dalia.hdf5')\n",
    "\n",
    "    y_activity1 = activity_estimator.predict(generated_X*cc).argmax(axis=1)\n",
    "    y_activity2 = activity_estimator.predict(X*cc).argmax(axis=1)\n",
    "    print(accuracy_score(y_participant,y_pred_original),'original',accuracy_score(y_participant,y_pred_gan),'GAN',\n",
    "          'activity_original',len(np.where(y_activity2==act_value)[0])/len(y_activity2),\n",
    "          'activity_pred',len(np.where(y_activity1==act_value)[0])/len(y_activity1),\n",
    "          ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "structured-enzyme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=float32, numpy=\n",
       "array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "premium-seminar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4696, 6), dtype=float32, numpy=\n",
       "array([[5.8870988e-05, 1.5368937e-01, 2.0252573e-01, 5.0645145e-03,\n",
       "        1.4673933e-01, 4.9192217e-01],\n",
       "       [1.6683087e-05, 6.6304496e-03, 7.3852665e-03, 7.2838092e-01,\n",
       "        2.9838135e-04, 2.5728819e-01],\n",
       "       [4.2903830e-06, 5.5490190e-04, 5.5177684e-04, 6.8937451e-02,\n",
       "        3.5401233e-03, 9.2641139e-01],\n",
       "       ...,\n",
       "       [2.9513585e-06, 4.5327572e-03, 3.2724267e-05, 2.9128048e-04,\n",
       "        7.3131606e-02, 9.2200863e-01],\n",
       "       [7.9734752e-09, 1.2022799e-03, 4.3547225e-06, 7.3267234e-04,\n",
       "        7.1318238e-04, 9.9734747e-01],\n",
       "       [2.6993728e-05, 1.4591870e-05, 1.2618382e-04, 9.8730022e-01,\n",
       "        4.7369234e-05, 1.2484715e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_estimator(generated_X*cc,training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "polyphonic-casino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=12.17736>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_walking = tf.zeros((200))\n",
    "\n",
    "a = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "a(y_walking.numpy(),generated_activity.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "narrow-casino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200, 6), dtype=float32, numpy=\n",
       "array([[3.1279203e-02, 7.3128838e-05, 6.2409025e-01, 1.2003756e-02,\n",
       "        3.2905170e-01, 3.5019042e-03],\n",
       "       [2.2907858e-05, 1.1204067e-02, 9.8560113e-01, 1.8217081e-05,\n",
       "        2.9932682e-03, 1.6036928e-04],\n",
       "       [7.3291776e-05, 3.1328050e-03, 9.9637467e-01, 1.1018338e-04,\n",
       "        2.6382686e-04, 4.5078024e-05],\n",
       "       ...,\n",
       "       [3.0994249e-07, 9.3808484e-01, 2.0014826e-02, 1.0046176e-05,\n",
       "        2.1188209e-02, 2.0701656e-02],\n",
       "       [5.8765731e-10, 9.9714112e-01, 3.0014402e-04, 3.9700876e-07,\n",
       "        6.4800668e-05, 2.4935910e-03],\n",
       "       [1.3815179e-05, 7.3480926e-02, 8.8256365e-01, 1.2438492e-05,\n",
       "        4.2613342e-02, 1.3158778e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-cuisine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
