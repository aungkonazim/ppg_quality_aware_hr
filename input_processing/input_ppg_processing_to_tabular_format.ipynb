{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filepath = '../data/8/'\n",
    "filelists = [filepath+a for a in os.listdir(filepath) if a[-1] not in ['s','f']]\n",
    "\n",
    "from datetime import datetime\n",
    "X_ppg = []\n",
    "X_acl = []\n",
    "y = []\n",
    "y_participant = []\n",
    "X_hr_windows = []\n",
    "import pickle\n",
    "for i,f in enumerate(filelists):\n",
    "    data = pickle.load(open(f,'rb'))\n",
    "    X_ppg.extend([a.values[:,1].reshape(1,-1,1) for a in data['data'].values])\n",
    "    X_acl.extend([a[:,1:].reshape(1,-1,3) for a in data['acc_window'].values])\n",
    "    y.extend(list(data['ecg_rr'].values))\n",
    "    y_participant.extend([i]*data.shape[0])\n",
    "    data['participant'] = i\n",
    "    data['timestamp'] = data['start_time'].apply(lambda a:datetime.utcfromtimestamp(a))\n",
    "    data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "    hr_windows = [df[['ecg_rr','participant']].values for i,df in \n",
    "                  data.groupby(pd.Grouper(key='timestamp',freq='20S')) if df.shape[0]==10]\n",
    "    X_hr_windows.extend(hr_windows)\n",
    "\n",
    "X_acl = np.concatenate(X_acl)\n",
    "X_ppg = np.concatenate(X_ppg)\n",
    "y = np.array(y)\n",
    "y_participant = np.array(y_participant)\n",
    "\n",
    "X_acl.shape,X_ppg.shape,y.shape,y_participant.shape\n",
    "\n",
    "import pickle\n",
    "pickle.dump([X_acl,X_ppg,y,y_participant],open('../data/tabular_data.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Zxx = signal.stft(X_acl, 32, nperseg=64,noverlap=32*1.75,nfft=5000,axis=1)\n",
    "plt.pcolormesh(t, f[f<4], np.abs(Zxx)[f<4], shading='gouraud')\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5001, 1, 33)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, t, Zxx = signal.stft(X_ppg[:20], 64, nperseg=128,noverlap=64*1.75,nfft=10000,axis=1)\n",
    "Zxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acl[0,:,0].reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_hr_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_hr_windows)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [a[:,1][0] for a in X_hr_windows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4325, 10), (4325,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler, MinMaxScaler,QuantileTransformer\n",
    "import pickle\n",
    "from scipy.stats import skew,kurtosis,iqr\n",
    "# from ecg import ecg_feature_computation\n",
    "import math\n",
    "# from hrvanalysis import remove_ectopic_beats\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score, \\\n",
    "recall_score,accuracy_score,auc,classification_report,make_scorer,roc_curve\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV, StratifiedKFold\n",
    "from sklearn import preprocessing,metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from joblib import Parallel,delayed\n",
    "delta = 0.1\n",
    "from sklearn.metrics import roc_curve,auc,make_scorer\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1Bias_scorer_CV(y_true,y_pred, ret_bias=False):\n",
    "    probs = y_true\n",
    "    y = y_pred\n",
    "    if not ret_bias:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        return auc(fpr,tpr)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y, probs)\n",
    "    \n",
    "    f1 = 0.0\n",
    "    for i in range(0, len(thresholds)):\n",
    "        if not (precision[i] == 0 and recall[i] == 0):\n",
    "            if np.abs(precision[i]-recall[i])<.1:\n",
    "                f = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "                if f > f1:\n",
    "                    f1 = f\n",
    "                    bias = thresholds[i]\n",
    "\n",
    "    if ret_bias:\n",
    "        return f1, bias\n",
    "    else:\n",
    "        return f1\n",
    "def get_results(X,y):\n",
    "    delta = 0.1\n",
    "    paramGrid = {\n",
    "            'svc__min_samples_leaf': [4],\n",
    "            'svc__max_features': [.7,1],\n",
    "            'svc__n_estimators': [100,200],\n",
    "            'svc__criterion':['gini','entropy'],\n",
    "    }\n",
    "    clf = Pipeline([('sts',StandardScaler()),('svc', RandomForestClassifier())])\n",
    "    gkf = StratifiedKFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(clf, paramGrid, n_jobs=-1,cv=list(gkf.split(X,y)),\n",
    "                               scoring='accuracy',verbose=5)\n",
    "    grid_search.fit(X,y)\n",
    "    clf = grid_search.best_estimator_\n",
    "    \n",
    "    probs = cross_val_predict(clf,X,y,cv=gkf.split(X,y),n_jobs=20)\n",
    "    y_pred = np.int64(probs)\n",
    "    print(classification_report(y,y_pred),confusion_matrix(y,y_pred))\n",
    "    return classification_report(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  40 | elapsed:    0.9s remaining:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  40 | elapsed:    2.6s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  40 | elapsed:    4.4s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  40 | elapsed:    6.2s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed:   16.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.09      0.05      0.07       261\n",
      "         1.0       0.30      0.34      0.32       320\n",
      "         2.0       0.07      0.08      0.08       261\n",
      "         3.0       0.75      0.59      0.66       324\n",
      "         4.0       0.05      0.01      0.02       261\n",
      "         5.0       0.20      0.35      0.26       352\n",
      "         6.0       0.14      0.07      0.10       295\n",
      "         7.0       0.14      0.24      0.18       276\n",
      "         8.0       0.26      0.34      0.29       273\n",
      "         9.0       0.21      0.21      0.21       311\n",
      "        10.0       0.11      0.05      0.07       280\n",
      "        11.0       0.12      0.15      0.13       260\n",
      "        12.0       0.14      0.07      0.09       272\n",
      "        13.0       0.14      0.20      0.17       303\n",
      "        14.0       0.09      0.10      0.09       276\n",
      "\n",
      "   micro avg       0.20      0.20      0.20      4325\n",
      "   macro avg       0.19      0.19      0.18      4325\n",
      "weighted avg       0.20      0.20      0.19      4325\n",
      " [[ 14   0  22   0   2  13   9  61  44   0  13  25   9  26  23]\n",
      " [  1 110   8  32   9  45  24  13   0  44   4   2   1  22   5]\n",
      " [ 14   2  22   1   0  25   3  64  16   3   3  38  10  34  26]\n",
      " [  2  39   5 191   9  11  16   9   8  13   2   2   4   8   5]\n",
      " [  2  60   7  12   3  47  15  14  16  31   7  15   6  18   8]\n",
      " [  3   6  23   1   5 122  15  10   3  57   4  18  20  42  23]\n",
      " [ 12  63  10  12   5  48  22  13  31  29  13  10   3  16   8]\n",
      " [ 35   0  44   0   1   4   0  66  40   0  15  28   4  12  27]\n",
      " [ 22   0  24   1   0   2   4  39  94   0  18  27   2   4  36]\n",
      " [  3  42  12   1   8  85   8  19  12  66   3   7  10  27   8]\n",
      " [ 10  24  25   0   6  32  14  35  31  17  13  18   6  22  27]\n",
      " [ 11   3  39   0   1  12   0  39  18   5   2  39  14  42  35]\n",
      " [  6   9  22   1   4  62   9  30  11  10   2  31  19  48   8]\n",
      " [  4   3  14   1   2  79   9  10   8  30   3  30  21  60  29]\n",
      " [ 15   0  39   0   2  11   6  41  34   2  17  41   6  35  27]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n         0.0       0.09      0.05      0.07       261\\n         1.0       0.30      0.34      0.32       320\\n         2.0       0.07      0.08      0.08       261\\n         3.0       0.75      0.59      0.66       324\\n         4.0       0.05      0.01      0.02       261\\n         5.0       0.20      0.35      0.26       352\\n         6.0       0.14      0.07      0.10       295\\n         7.0       0.14      0.24      0.18       276\\n         8.0       0.26      0.34      0.29       273\\n         9.0       0.21      0.21      0.21       311\\n        10.0       0.11      0.05      0.07       280\\n        11.0       0.12      0.15      0.13       260\\n        12.0       0.14      0.07      0.09       272\\n        13.0       0.14      0.20      0.17       303\\n        14.0       0.09      0.10      0.09       276\\n\\n   micro avg       0.20      0.20      0.20      4325\\n   macro avg       0.19      0.19      0.18      4325\\nweighted avg       0.20      0.20      0.19      4325\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
